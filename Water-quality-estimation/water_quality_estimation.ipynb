{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/dat-a-thon23'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-21T10:49:06.202352Z","iopub.execute_input":"2023-03-21T10:49:06.202776Z","iopub.status.idle":"2023-03-21T10:49:06.237850Z","shell.execute_reply.started":"2023-03-21T10:49:06.202734Z","shell.execute_reply":"2023-03-21T10:49:06.236517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dense\nimport csv\n\ntf.keras.backend.set_floatx('float64') #sets the keras data-type for model layers to float64. The default is float32\n","metadata":{"execution":{"iopub.status.busy":"2023-03-21T10:50:48.392869Z","iopub.execute_input":"2023-03-21T10:50:48.393543Z","iopub.status.idle":"2023-03-21T10:50:58.290104Z","shell.execute_reply.started":"2023-03-21T10:50:48.393485Z","shell.execute_reply":"2023-03-21T10:50:58.288135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/dat-a-thon23/train.csv') \nprint(df1.isnull().values.any()) #prints 'True' if there are any missing values in the data frame, 'False' if no missing value is there\ndf = df1.dropna().reset_index(drop=True) #drop rows with missing entries\nprint(df.isnull().values.any())\n\nSize = df.shape[0] #train.csv has 13000 entries. Since the entries with missing data are removed, the size changes to 12936\nprint(Size)\nFeature_size = 26 #Number of input features is 26\nOUT = np.zeros(Size, dtype=float)\nIN = np.zeros((Size, Feature_size),  dtype=float)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-21T10:51:21.726251Z","iopub.execute_input":"2023-03-21T10:51:21.727085Z","iopub.status.idle":"2023-03-21T10:51:21.920182Z","shell.execute_reply.started":"2023-03-21T10:51:21.727043Z","shell.execute_reply":"2023-03-21T10:51:21.918938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in range(Size):\n  #print(x)\n  categoryA = (df['categoryA'][x])\n  categoryB = (df['categoryB'][x])\n  categoryC = (df['categoryC'][x])\n  categoryD = (df['categoryD'][x])\n  categoryE = (df['categoryE'][x])\n  categoryF = (df['categoryF'][x])\n  unit = (df['unit'][x])\n  in0 = float(categoryA.split(\"_\")[1])\n  in1 = float(categoryB.split(\"_\")[1])\n  in2 = float(categoryC.split(\"_\")[1])\n  in3 = float(categoryD.split(\"_\")[1])\n  in4 = float(categoryE.split(\"_\")[1])\n  in5 = float(categoryF.split(\"_\")[1])\n  in6 = float(df['featureA'][x])\n  #print(in6)\n  in7 = float(df['featureB'][x])\n  in8 = float(df['featureC'][x])\n  in9 = float(df['featureD'][x])\n  in10 = float(df['featureE'][x])\n  in11 = float(df['featureF'][x])\n  in12 = float(df['featureG'][x])\n  in13 = float(df['featureH'][x])\n  in14 = float(df['featureI'][x])\n  in15 = float(df['compositionA'][x])\n  in16 = float(df['compositionB'][x])\n  in17 = float(df['compositionC'][x])\n  in18 = float(df['compositionD'][x])\n  in19 = float(df['compositionE'][x])\n  in20 = float(df['compositionF'][x])\n  in21 = float(df['compositionG'][x])\n  in22 = float(df['compositionH'][x])\n  in23 = float(df['compositionI'][x])\n  in24 = float(df['compositionJ'][x])\n  in25 = float(unit.split(\"_\")[1])\n  result = float(df['result'][x])\n  OUT[x] = result\n  IN[x,0] = in0\n  IN[x,1] = in1\n  IN[x,2] = in2\n  IN[x,3] = in3\n  IN[x,4] = in4\n  IN[x,5] = in5\n  IN[x,6] = in6\n  IN[x,7] = in7\n  IN[x,8] = in8\n  IN[x,9] = in9\n  IN[x,10] = in10\n  IN[x,11] = in11\n  IN[x,12] = in12\n  IN[x,13] = in13\n  IN[x,14] = in14\n  IN[x,15] = in15\n  IN[x,16] = in16\n  IN[x,17] = in17\n  IN[x,18] = in18\n  IN[x,19] = in19\n  IN[x,20] = in20\n  IN[x,21] = in21\n  IN[x,22] = in22\n  IN[x,23] = in23\n  IN[x,24] = in24\n  IN[x,25] = in25\ndef my_norm(arr):\n  return (arr-np.mean(arr))/np.std(arr)\n\nIN[:,0] = my_norm(IN[:,0])\nIN[:,1] = my_norm(IN[:,1])\nIN[:,2] = my_norm(IN[:,2])\nIN[:,3] = my_norm(IN[:,3])\nIN[:,4] = my_norm(IN[:,4])\nIN[:,5] = my_norm(IN[:,5])\nIN[:,6] = my_norm(IN[:,6])\nIN[:,7] = my_norm(IN[:,7])\nIN[:,8] = my_norm(IN[:,8])\nIN[:,9] = my_norm(IN[:,9])\nIN[:,10] = my_norm(IN[:,10])\nIN[:,11] = my_norm(IN[:,11])\nIN[:,12] = my_norm(IN[:,12])\nIN[:,13] = my_norm(IN[:,13])\nIN[:,14] = my_norm(IN[:,14])\nIN[:,15] = my_norm(IN[:,15])\nIN[:,16] = my_norm(IN[:,16])\nIN[:,17] = my_norm(IN[:,17])\nIN[:,18] = my_norm(IN[:,18])\nIN[:,19] = my_norm(IN[:,19])\nIN[:,20] = my_norm(IN[:,20])\nIN[:,21] = my_norm(IN[:,21])\nIN[:,22] = my_norm(IN[:,22])\nIN[:,23] = my_norm(IN[:,23])\nIN[:,24] = my_norm(IN[:,24])\nIN[:,25] = my_norm(IN[:,25])\n\nprint(IN.shape)\nprint(OUT.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-21T10:51:26.695731Z","iopub.execute_input":"2023-03-21T10:51:26.696367Z","iopub.status.idle":"2023-03-21T10:51:29.155908Z","shell.execute_reply.started":"2023-03-21T10:51:26.696319Z","shell.execute_reply":"2023-03-21T10:51:29.154742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###Define Model\ndef get_model():\n    input0 = keras.Input(shape=(26))\n\n    #x0 = layers.Dense(1)(input0) #Same as linear regression\n    x0 = layers.Dense(512, activation='relu')(input0)\n    x0 = layers.Dense(256, activation='relu')(x0)\n    x0 = layers.Dense(128, activation='relu')(x0)\n    #x0 = layers.Dense(128, activation='relu')(x0)\n    #x0 = layers.Dense(128, activation='relu')(x0)\n    x0 = layers.Dense(64, activation='relu')(x0)\n    x0 = layers.Dense(1)(x0)\n    outputs = x0\n\n    return keras.Model(input0, outputs)\n\nmodel = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-21T10:51:43.369549Z","iopub.execute_input":"2023-03-21T10:51:43.369985Z","iopub.status.idle":"2023-03-21T10:51:43.670219Z","shell.execute_reply.started":"2023-03-21T10:51:43.369949Z","shell.execute_reply":"2023-03-21T10:51:43.668694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\nmodel.fit(IN, OUT, epochs=1000)\n#model.save_weights(\"ckpt_1/model1.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T10:52:00.164820Z","iopub.execute_input":"2023-03-21T10:52:00.165608Z","iopub.status.idle":"2023-03-21T10:52:28.023104Z","shell.execute_reply.started":"2023-03-21T10:52:00.165544Z","shell.execute_reply":"2023-03-21T10:52:28.021615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load test data\ndf2 = pd.read_csv('/kaggle/input/dat-a-thon23/test.csv')\ndf2.fillna(0,inplace=True) #put '0' for missing entries\nSize2 = 7000\nFeature_size = 26\nTEST_IN = np.zeros((Size2, Feature_size),  dtype=float)\n\nfor x in range(Size2):\n  #print(x)\n  categoryA = (df2['categoryA'][x])\n  categoryB = (df2['categoryB'][x])\n  categoryC = (df2['categoryC'][x])\n  categoryD = (df2['categoryD'][x])\n  categoryE = (df2['categoryE'][x])\n  categoryF = (df2['categoryF'][x])\n  unit = (df2['unit'][x])\n  in0 = float(categoryA.split(\"_\")[1])\n  in1 = float(categoryB.split(\"_\")[1])\n  in2 = float(categoryC.split(\"_\")[1])\n  in3 = float(categoryD.split(\"_\")[1])\n  in4 = float(categoryE.split(\"_\")[1])\n  in5 = float(categoryF.split(\"_\")[1])\n  in6 = float(df2['featureA'][x])\n  in7 = float(df2['featureB'][x])\n  in8 = float(df2['featureC'][x])\n  in9 = float(df2['featureD'][x])\n  in10 = float(df2['featureE'][x])\n  in11 = float(df2['featureF'][x])\n  in12 = float(df2['featureG'][x])\n  in13 = float(df2['featureH'][x])\n  in14 = float(df2['featureI'][x])\n  in15 = float(df2['compositionA'][x])\n  in16 = float(df2['compositionB'][x])\n  in17 = float(df2['compositionC'][x])\n  in18 = float(df2['compositionD'][x])\n  in19 = float(df2['compositionE'][x])\n  in20 = float(df2['compositionF'][x])\n  in21 = float(df2['compositionG'][x])\n  in22 = float(df2['compositionH'][x])\n  in23 = float(df2['compositionI'][x])\n  in24 = float(df2['compositionJ'][x])\n  in25 = float(unit.split(\"_\")[1])\n  TEST_IN[x,0] = in0\n  TEST_IN[x,1] = in1\n  TEST_IN[x,2] = in2\n  TEST_IN[x,3] = in3\n  TEST_IN[x,4] = in4\n  TEST_IN[x,5] = in5\n  TEST_IN[x,6] = in6\n  TEST_IN[x,7] = in7\n  TEST_IN[x,8] = in8\n  TEST_IN[x,9] = in9\n  TEST_IN[x,10] = in10\n  TEST_IN[x,11] = in11\n  TEST_IN[x,12] = in12\n  TEST_IN[x,13] = in13\n  TEST_IN[x,14] = in14\n  TEST_IN[x,15] = in15\n  TEST_IN[x,16] = in16\n  TEST_IN[x,17] = in17\n  TEST_IN[x,18] = in18\n  TEST_IN[x,19] = in19\n  TEST_IN[x,20] = in20\n  TEST_IN[x,21] = in21\n  TEST_IN[x,22] = in22\n  TEST_IN[x,23] = in23\n  TEST_IN[x,24] = in24\n  TEST_IN[x,25] = in25\n\ndef my_norm1(arr2, arr1):\n  return (arr1-np.mean(arr2))/np.std(arr2)\n\nTEST_IN[:,0] = my_norm1(IN[:,0], TEST_IN[:,0])\nTEST_IN[:,1] = my_norm1(IN[:,1], TEST_IN[:,1])\nTEST_IN[:,2] = my_norm1(IN[:,2], TEST_IN[:,2])\nTEST_IN[:,3] = my_norm1(IN[:,3], TEST_IN[:,3])\nTEST_IN[:,4] = my_norm1(IN[:,4], TEST_IN[:,4])\nTEST_IN[:,5] = my_norm1(IN[:,5], TEST_IN[:,5])\nTEST_IN[:,6] = my_norm1(IN[:,6], TEST_IN[:,6])\nTEST_IN[:,7] = my_norm1(IN[:,7], TEST_IN[:,7])\nTEST_IN[:,8] = my_norm1(IN[:,8], TEST_IN[:,8])\nTEST_IN[:,9] = my_norm1(IN[:,9], TEST_IN[:,9])\nTEST_IN[:,10] = my_norm1(IN[:,10], TEST_IN[:,10])\nTEST_IN[:,11] = my_norm1(IN[:,11], TEST_IN[:,11])\nTEST_IN[:,12] = my_norm1(IN[:,12], TEST_IN[:,12])\nTEST_IN[:,13] = my_norm1(IN[:,13], TEST_IN[:,13])\nTEST_IN[:,14] = my_norm1(IN[:,14], TEST_IN[:,14])\nTEST_IN[:,15] = my_norm1(IN[:,15], TEST_IN[:,15])\nTEST_IN[:,16] = my_norm1(IN[:,16], TEST_IN[:,16])\nTEST_IN[:,17] = my_norm1(IN[:,17], TEST_IN[:,17])\nTEST_IN[:,18] = my_norm1(IN[:,18], TEST_IN[:,18])\nTEST_IN[:,19] = my_norm1(IN[:,19], TEST_IN[:,19])\nTEST_IN[:,20] = my_norm1(IN[:,20], TEST_IN[:,20])\nTEST_IN[:,21] = my_norm1(IN[:,21], TEST_IN[:,21])\nTEST_IN[:,22] = my_norm1(IN[:,22], TEST_IN[:,22])\nTEST_IN[:,23] = my_norm1(IN[:,23], TEST_IN[:,23])\nTEST_IN[:,24] = my_norm1(IN[:,24], TEST_IN[:,24])\nTEST_IN[:,25] = my_norm1(IN[:,25], TEST_IN[:,25])    \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-03-21T10:53:01.021783Z","iopub.execute_input":"2023-03-21T10:53:01.022332Z","iopub.status.idle":"2023-03-21T10:53:02.373853Z","shell.execute_reply.started":"2023-03-21T10:53:01.022279Z","shell.execute_reply":"2023-03-21T10:53:02.372535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open(\"out_val1.csv\", 'w')\nwriter = csv.writer(f)\ndata = ['id','result']\nwriter.writerow(data)\nfor x in range(Size):\n  prediction = model.predict(np.expand_dims(TEST_IN[x], axis=0))\n  pred = np.abs(prediction[0])\n  id = (df['id'][x])\n  data = [id,pred[0]]\n  writer.writerow(data)\nf.close()\n","metadata":{},"execution_count":null,"outputs":[]}]}